{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7JRkyCUChdIwqf9f3Zlen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjpritchard2001/MSBA-Team-14/blob/main/PerishableGoodsReinforcementLearningEx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bdq6jPCwQB5T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define the environment for perishable goods pricing\n",
        "class PerishableGoodsEnvironment:\n",
        "    def __init__(self, max_shelf_life, max_price, min_price):\n",
        "        self.max_shelf_life = max_shelf_life  # Max number of days the product lasts\n",
        "        self.max_price = max_price  # Maximum price for the product\n",
        "        self.min_price = min_price  # Minimum price for the product\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.shelf_life = self.max_shelf_life  # Reset shelf life to max at the start\n",
        "        self.price = random.uniform(self.min_price, self.max_price)  # Random initial price\n",
        "        return self.shelf_life\n",
        "\n",
        "    def step(self, action):\n",
        "        # Action is price, modify shelf life based on this action\n",
        "        self.price = np.clip(action, self.min_price, self.max_price)\n",
        "\n",
        "        # Calculate demand and reward based on price and shelf life\n",
        "        demand = self.calculate_demand(self.price)\n",
        "        reward = demand * self.price  # Revenue = price * demand\n",
        "\n",
        "        # Decrease shelf life by 1 day\n",
        "        self.shelf_life -= 1\n",
        "\n",
        "        # If the product has expired, return negative reward\n",
        "        if self.shelf_life <= 0:\n",
        "            reward -= 50  # Penalty for expired goods\n",
        "\n",
        "        done = self.shelf_life <= 0  # Episode ends if the product expires\n",
        "\n",
        "        return self.shelf_life, reward, done\n",
        "\n",
        "    def calculate_demand(self, price):\n",
        "        # A simple demand function that decreases with increasing price\n",
        "        # Demand is higher when the price is low and lower when price is high\n",
        "        max_demand = 100  # Max demand when price is at min price\n",
        "        demand = max_demand * (self.max_price - price) / (self.max_price - self.min_price)\n",
        "        return max(0, demand)  # Ensure demand is non-negative"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QLearningAgent:\n",
        "    def __init__(self, action_space, learning_rate=0.1, discount_factor=0.9, exploration_rate=1.0, exploration_decay=0.995):\n",
        "        self.action_space = action_space  # Set of possible prices\n",
        "        self.learning_rate = learning_rate  # Learning rate\n",
        "        self.discount_factor = discount_factor  # Discount factor for future rewards\n",
        "        self.exploration_rate = exploration_rate  # Exploration-exploitation tradeoff\n",
        "        self.exploration_decay = exploration_decay  # Decay of exploration rate\n",
        "        self.q_table = np.zeros(len(action_space))  # Q-table initialization\n",
        "\n",
        "    def choose_action(self):\n",
        "        if random.uniform(0, 1) < self.exploration_rate:\n",
        "            # Exploration: choose random action (price)\n",
        "            return random.choice(self.action_space)\n",
        "        else:\n",
        "            # Exploitation: choose action with the highest Q-value\n",
        "            return self.action_space[np.argmax(self.q_table)]\n",
        "\n",
        "    def learn(self, state, action, reward, next_state):\n",
        "        # Use np.where to find the index of the action in action_space\n",
        "        action_index = np.where(self.action_space == action)[0][0]\n",
        "        next_best_action = np.argmax(self.q_table)  # Best future action\n",
        "\n",
        "        # Update Q-value using the Q-learning update rule\n",
        "        self.q_table[action_index] += self.learning_rate * (reward + self.discount_factor * self.q_table[next_best_action] - self.q_table[action_index])\n",
        "\n",
        "        # Decay the exploration rate to shift towards exploitation over time\n",
        "        self.exploration_rate *= self.exploration_decay"
      ],
      "metadata": {
        "id": "aZ_RinNhQNFo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the environment and agent\n",
        "max_shelf_life = 10  # Product shelf life in days\n",
        "max_price = 20  # Maximum price\n",
        "min_price = 5  # Minimum price\n",
        "action_space = np.linspace(min_price, max_price, 20)  # Possible prices\n",
        "\n",
        "# Initialize environment and agent\n",
        "env = PerishableGoodsEnvironment(max_shelf_life, max_price, min_price)\n",
        "agent = QLearningAgent(action_space)\n",
        "\n",
        "# Training loop\n",
        "num_episodes = 5000\n",
        "for episode in range(num_episodes):\n",
        "    state = env.reset()  # Reset the environment\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "\n",
        "    while not done:\n",
        "        action = agent.choose_action()  # Choose an action (price)\n",
        "        next_state, reward, done = env.step(action)  # Take a step in the environment\n",
        "        agent.learn(state, action, reward, next_state)  # Update the agent's Q-table\n",
        "\n",
        "        state = next_state  # Move to the next state\n",
        "        total_reward += reward  # Accumulate reward for this episode\n",
        "\n",
        "    # Optionally, print out progress\n",
        "    if episode % 1000 == 0:\n",
        "        print(f\"Episode {episode}/{num_episodes} - Total Reward: {total_reward}\")\n",
        "\n",
        "print(\"Training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6mdLRxeQN80",
        "outputId": "8a31c612-7e9c-492f-902d-e1fcb5a56ea4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0/5000 - Total Reward: 4443.074792243768\n",
            "Episode 1000/5000 - Total Reward: 6390.4432132964\n",
            "Episode 2000/5000 - Total Reward: 6390.4432132964\n",
            "Episode 3000/5000 - Total Reward: 6390.4432132964\n",
            "Episode 4000/5000 - Total Reward: 6390.4432132964\n",
            "Training complete.\n"
          ]
        }
      ]
    }
  ]
}